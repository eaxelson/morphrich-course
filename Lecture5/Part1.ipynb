{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MORPHOLOGICALLY RICH LANGUAGES WITH HFST TOOLS - LECTURE 5\n",
    "\n",
    "Topics:\n",
    "\n",
    "* Twolc & xfst rewrite rules\n",
    "\n",
    "TODO: demonstrate how twolc rules can be generated with hfst_dev.regex('').\n",
    "\n",
    "<ul>\n",
    "<li>1. <a href=\"#1.-Twolc-formalism\">Twolc formalism</a></li>\n",
    "<li>2. <a href=\"#2.-Twolc-rewrite-rules-for-Olonets-Karelian\">Twolc rewrite rules for Olonets-Karelian</a></li>\n",
    "<li>3. <a href=\"#3.-Xfst-rewrite-rules\">Xfst rewrite rules</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Twolc formalism\n",
    "\n",
    "A twol-grammar consists of five parts: Alphabet, Diacritics, Sets, Definitions and Rules.\n",
    "Each part contains statements, that end in a ; character and comments, that begin with a ! character and span to the end of the line.\n",
    "Two-level rules consist of a center, a rule-operator and contexts.\n",
    "Twolc is often used for writing phonological rules that are applied to a lexicon written in lexc.\n",
    "\n",
    "A minimalistic example of lexc combined with twolc:\n",
    "\n",
    "lexc file:\n",
    "```\n",
    "LEXICON Root\n",
    "kaNpa # ;\n",
    "```\n",
    "\n",
    "twolc file (n2m.twolc):\n",
    "```\n",
    "Alphabet a k m n p N ;\n",
    "Rules\n",
    "\"N to m\"\n",
    "N:m <=> _ :p ;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import compile_lexc_script\n",
    "lexicon = compile_lexc_script(\"\"\"\n",
    "LEXICON Root\n",
    "kaNpa # ;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import compile_twolc_file, HfstInputStream\n",
    "compile_twolc_file('n2m.twolc','n2m.hfst',verbose=True)\n",
    "istr = HfstInputStream('n2m.hfst')\n",
    "rules = istr.read_all()\n",
    "istr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon.compose_intersect(rules)\n",
    "print(lexicon.lookup('kaNpa'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is (('kampa', 0.0),).\n",
    "\n",
    "For more information about twolc, see <a href=\"https://github.com/hfst/hfst/wiki/HfstTwolc#syntax\">hfst-twolc command line tool manual page</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Twolc rewrite rules for Olonets-Karelian\n",
    "\n",
    "From the previous lecture:\n",
    "\n",
    "> ```# First, compile the lexc files:```\n",
    "> \n",
    "> ```# TODO: cat root.lexc kala.lexc nouns.lexc clitics.lexc > root_kala_nouns_clitics.lexc\n",
    "> from hfst_dev import compile_lexc_file, HfstTransducer```\n",
    "> \n",
    "> ```kala = compile_lexc_file('root_kala_nouns_clitics.lexc')\n",
    "> print(kala.lookup('kala+N+Pl+Ade'))```\n",
    ">\n",
    "> ```# Without the rules, the result is (('kala{back}^A2O>i>l', 0.0),)```\n",
    "\n",
    "Have a look at Olonetsian Karelian lexc files in Giella repo that we used in the previous lecture\n",
    "as well as the twolc file olo-phon.twolc:\n",
    "\n",
    "* <a href=\"https://victorio.uit.no/langtech/trunk/langs/olo/src/morphology/stems/nouns.lexc\">stems/nouns.lexc</a>\n",
    "* <a href=\"https://victorio.uit.no/langtech/trunk/langs/olo/src/morphology/affixes/nouns.lexc\">affixes/nouns.lexc</a>\n",
    "* <a href=\"https://victorio.uit.no/langtech/trunk/langs/olo/src/morphology/affixes/clitics.lexc\">affixes/clitics.lexc</a>\n",
    "* <a href=\"https://victorio.uit.no/langtech/trunk/langs/olo/src/phonology/olo-phon.twolc\">olo-phon.twolc</a>\n",
    "\n",
    "or use a copies available in this directory. We will use a simplified test case where stems/nouns.lexc will be\n",
    "replaced with a single-stem file kala.lexc as we did in Lecture 4:\n",
    "\n",
    "```\n",
    "LEXICON nouns\n",
    "kala+N:kala N_KALA ;\n",
    "```\n",
    "\n",
    "Remember that multicharacter symbols and root and end lexica are listed in file\n",
    "<a href=\"https://victorio.uit.no/langtech/trunk/langs/olo/src/morphology/root.lexc\">root.lexc</a>.\n",
    "\n",
    "We use again the affix and clitics files as such."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, compile the lexc files as we did in Lecture 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: we have to catenate the files: cat root.lexc kala.lexc nouns.lexc clitics.lexc > root_kala_nouns_clitics.lexc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import compile_lexc_file\n",
    "kala = compile_lexc_file('root_kala_nouns_clitics.lexc')\n",
    "print(kala.lookup('kala+N+Pl+Ade'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without the rules, the result is (('kala{back}^A2O>i>l', 0.0),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We introduce phonological rewrite rules given in file olo-phon.twolc. Note e.g.:\n",
    "\n",
    "```\n",
    "\"a:o in the plural and preterite\"\n",
    "!! __@RULENAME@__\n",
    "a:o <=> Cns: _ (%{back%}:) (%^WGStem:) %^A2O: ;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then compile twolc rules (TODO: result is written to file):\n",
    "This takes some time and we get verbose output (TODO: use python's stdout in hfst_dev module...):\n",
    "\n",
    "```\n",
    "Reading alphabet.\n",
    "Reading sets.\n",
    "Reading and compiling definitions.\n",
    "Reading rules and compiling their contexts and centers.\n",
    "Compiling rules.\n",
    "Storing rules.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_twolc_file('olo-phon.twolc','olo-phon.hfst',verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "istr = HfstInputStream('olo-phon.hfst')\n",
    "rules = istr.read_all()\n",
    "istr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get 86 rules in total:\n",
    "print(len(rules))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compose-intersect the lexicon with the rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kala.compose_intersect(rules)\n",
    "print(kala.lookup('kala+N+Pl+Ade'))\n",
    "print(kala.lookup('kala+N+Pl+Abl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and get the result ```(('kalo>i>l', 0.0),)``` ('>' means morpheme boundary). Compare with test file lines:\n",
    "\n",
    "```\n",
    "kala+N+Pl+Ade: kaloil\n",
    "kala+N+Pl+Abl: [kaloilpÃ¤i, kaloil]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for testcase in ('kala+N+Pl+Ade','kala+N+Pl+Abl'):\n",
    "    results = kala.lookup(testcase)\n",
    "    for res in results:\n",
    "        print(res[0].replace('>',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of morpheme boundary '>'.\n",
    "from hfst_dev import EPSILON\n",
    "kala.substitute('>',EPSILON)\n",
    "kala.minimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that each generated form produced by kala is listed\n",
    "as a possible result in yaml file (TODO: a separate function for this?):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"N-kala_gt-norm.yaml\", \"r\") as myfile:\n",
    "    data=myfile.readlines()\n",
    "for line in data:\n",
    "    if '     ' in line:\n",
    "        # kala+N+Sg+Abe: [kalata, kalattah]\n",
    "        pair = line.split(': ')\n",
    "        # 'kala+N+Sg+Abe'\n",
    "        analysis = pair[0].replace('     ','')\n",
    "        # ('kalata', 'kalattah')\n",
    "        generation = pair[1].replace('\\n','').replace('[','').replace(']','').split(', ')\n",
    "        results = kala.lookup(analysis)\n",
    "        for res in results:\n",
    "            # res[0] is the output form, res[1] is the weight\n",
    "            if res[0] not in generation:\n",
    "                print('unknown result for analysis \"' + analysis + '\": \"' + res[0] + '\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invert the generator to get an analyser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kala.invert()\n",
    "kala.minimize()\n",
    "print(kala.lookup('kaloil'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Xfst rewrite rules\n",
    "\n",
    "Rewrite rules can also be written using the xfst formalism.\n",
    "\n",
    "The \"N to m\" rule ```# N:m <=> _ :p ;``` would be:\n",
    "\n",
    "```\n",
    "N -> m || _ p ;\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
