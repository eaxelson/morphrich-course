{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MORPHOLOGICALLY RICH LANGUAGES WITH HFST TOOLS - LECTURE 5\n",
    "\n",
    "Topics: Twolc & xfst rewrite rules\n",
    "\n",
    "<ul>\n",
    "<li>1. <a href=\"#1.-Twolc-formalism\">Twolc formalism</a></li>\n",
    "<li>2. <a href=\"#2.-Twolc-rewrite-rules-for-Olonets-Karelian\">Twolc rewrite rules for Olonets Karelian</a></li>\n",
    "<li>3. <a href=\"#3.-Twolc-vs.-xfst-rewrite-rules\">Twolc vs. xfst rewrite rules (TODO)</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Twolc formalism\n",
    "\n",
    "A twol-grammar consists of five parts: `Alphabet`, `Diacritics`, `Sets`, `Definitions` and `Rules`.\n",
    "Each part contains statements that end in `;`, possibly followed by comments that begin with `!` and span to the end of the line.\n",
    "Two-level rules consist of a center, a rule-operator and contexts.\n",
    "Twolc is often used for writing phonological rules that are applied to a lexicon written in lexc.\n",
    "The rules are applied via intersection instead of composition. (TODO: explain more?)\n",
    "\n",
    "A minimalistic example of lexc combined with twolc:\n",
    "\n",
    "lexc script containing one entry `kaNpa`:\n",
    "```\n",
    "LEXICON Root\n",
    "kaNpa # ;\n",
    "```\n",
    "\n",
    "twolc script (available in file <i>n2m.twolc</i>) that rewrites (is this the correct term?)\n",
    "`N` to `m` before `p`:\n",
    "```\n",
    "Alphabet a k m n p N ;\n",
    "Rules\n",
    "\"N to m\"\n",
    "N:m <=> _ :p ;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import compile_lexc_script\n",
    "lexicon = compile_lexc_script(\"\"\"\n",
    "LEXICON Root\n",
    "kaNpa # ;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement also function compile_twolc_script\n",
    "# TODO: rewrite compile_twolc_file so that it returns the result instead of writing it to file\n",
    "from hfst_dev import compile_twolc_file, HfstInputStream\n",
    "compile_twolc_file('n2m.twolc','n2m.hfst',verbose=True)\n",
    "istr = HfstInputStream('n2m.hfst')\n",
    "rules = istr.read_all()\n",
    "istr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon.compose_intersect(rules)\n",
    "print(lexicon.lookup('kaNpa'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is (('kampa', 0.0),).\n",
    "\n",
    "For more information about twolc, see <a href=\"https://github.com/hfst/hfst/wiki/HfstTwolc#syntax\">hfst-twolc command line tool manual page</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Twolc rewrite rules for Olonets Karelian\n",
    "\n",
    "From the previous lecture:\n",
    "\n",
    "> ```# First, compile the lexc files:```\n",
    "> \n",
    "> from hfst_dev import compile_lexc_files, HfstTransducer```\n",
    "> \n",
    "> ```kala = compile_lexc_files(('root.lexc','kala.lexc','nouns.lexc','clitics.lexc'))\n",
    "> print(kala.lookup('kala+N+Pl+Ade'))```\n",
    ">\n",
    "> ```# Without the rules, the result is (('kala{back}^A2O>i>l', 0.0),)```\n",
    "\n",
    "Have a look at Olonets Karelian lexc files in Giella repo that we used in the previous lecture\n",
    "as well as the twolc file <i>olo-phon.twolc</i>:\n",
    "\n",
    "* <a href=\"https://victorio.uit.no/langtech/trunk/langs/olo/src/morphology/stems/nouns.lexc\">stems/nouns.lexc</a> (was replaced with <i>kala.lexc</i>)\n",
    "* <a href=\"https://victorio.uit.no/langtech/trunk/langs/olo/src/morphology/affixes/nouns.lexc\">affixes/nouns.lexc</a>\n",
    "* <a href=\"https://victorio.uit.no/langtech/trunk/langs/olo/src/morphology/affixes/clitics.lexc\">affixes/clitics.lexc</a>\n",
    "* <a href=\"https://victorio.uit.no/langtech/trunk/langs/olo/src/phonology/olo-phon.twolc\">olo-phon.twolc</a>\n",
    "\n",
    "or use a copies available in this directory. We will use a simplified test case where <i>stems/nouns.lexc</i> will be\n",
    "replaced with a single-stem file <i>kala.lexc</i> as we did in Lecture 4:\n",
    "\n",
    "```\n",
    "LEXICON nouns\n",
    "kala+N:kala N_KALA ;\n",
    "```\n",
    "\n",
    "Remember that multicharacter symbols and root and end lexica are listed in file <i>root.lexc</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, compile the lexc files as we did in Lecture 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import compile_lexc_files\n",
    "kala = compile_lexc_files(('root.lexc','kala.lexc','nouns.lexc','clitics.lexc'))\n",
    "print(kala.lookup('kala+N+Pl+Ade'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without the rules, the result is (('kala{back}^A2O>i>l', 0.0),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We introduce phonological rewrite rules given in file <i>olo-phon.twolc</i>. Note e.g.:\n",
    "\n",
    "```\n",
    "\"a:o in the plural and preterite\"\n",
    "!! __@RULENAME@__\n",
    "a:o <=> Cns: _ (%{back%}:) (%^WGStem:) %^A2O: ;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then compile twolc rules. This takes some time and we get verbose output\n",
    "(TODO: use python's stdout in hfst_dev module so that the output will actually show...):\n",
    "\n",
    "```\n",
    "Reading alphabet.\n",
    "Reading sets.\n",
    "Reading and compiling definitions.\n",
    "Reading rules and compiling their contexts and centers.\n",
    "Compiling rules.\n",
    "Storing rules.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_twolc_file('olo-phon.twolc','olo-phon.hfst',verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "istr = HfstInputStream('olo-phon.hfst')\n",
    "rules = istr.read_all()\n",
    "istr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get 86 rules in total:\n",
    "print(len(rules))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compose-intersect the lexicon with the rules (TODO: explain what compose-intersection does)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kala.compose_intersect(rules)\n",
    "print(kala.lookup('kala+N+Pl+Ade'))\n",
    "print(kala.lookup('kala+N+Pl+Abl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and get the result `(('kalo>i>l', 0.0),)` ('>' means morpheme boundary).\n",
    "Compare the results with test file lines:\n",
    "\n",
    "```\n",
    "kala+N+Pl+Ade: kaloil\n",
    "kala+N+Pl+Abl: [kaloilpÃ¤i, kaloil]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for testcase in ('kala+N+Pl+Ade','kala+N+Pl+Abl'):\n",
    "    results = kala.lookup(testcase)\n",
    "    for res in results:\n",
    "        print(res[0].replace('>',''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of morpheme boundary '>' so we don't have to replace it every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfst_dev import EPSILON\n",
    "kala.substitute('>',EPSILON)\n",
    "kala.minimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that each generated form produced by kala is listed\n",
    "as a possible result in yaml test file <i>N-kala_gt-norm.yaml</i>\n",
    "(TODO: implement a separate function for this in hfst_dev module):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"N-kala_gt-norm.yaml\", \"r\") as myfile:\n",
    "    data=myfile.readlines()\n",
    "for line in data:\n",
    "    if '     ' in line:\n",
    "        # kala+N+Sg+Abe: [kalata, kalattah]\n",
    "        pair = line.split(': ')\n",
    "        # 'kala+N+Sg+Abe'\n",
    "        analysis = pair[0].replace('     ','')\n",
    "        # ('kalata', 'kalattah')\n",
    "        generation = pair[1].replace('\\n','').replace('[','').replace(']','').split(', ')\n",
    "        results = kala.lookup(analysis)\n",
    "        for res in results:\n",
    "            # res[0] is the output form, res[1] is the weight\n",
    "            # TODO: maybe the result should be a class?\n",
    "            if res[0] not in generation:\n",
    "                print('unknown result for analysis \"' + analysis + '\": \"' + res[0] + '\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invert the generator to get an analyser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kala.invert()\n",
    "kala.minimize()\n",
    "print(kala.lookup('kaloil'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Twolc vs. xfst rewrite rules\n",
    "\n",
    "TODO: Explain the differences between twolc and xfst formalism.\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
